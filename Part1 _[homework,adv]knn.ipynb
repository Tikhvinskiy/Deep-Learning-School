{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"[homework,adv]knn.ipynb\"","provenance":[{"file_id":"1mnv7T3RyKX9cQoJJXlTBMXMD7H2uKgDx","timestamp":1614864797182}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pgFYFftQKxY5"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:450px;\" width=500/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n","<h3 style=\"text-align: center;\"><b>Базовый поток. Осень 2020</b></h3>\n","\n","<h1 style=\"text-align: center;\"><b>Домашнее задание. Библиотека sklearn и классификация с помощью KNN</b></h1>"]},{"cell_type":"code","metadata":{"id":"9TYfXkZvc0tM"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4RCHGZULaWz"},"source":["На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."]},{"cell_type":"markdown","metadata":{"id":"F2acNQu1L94J"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Twe_cnn5KxY6"},"source":["<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"YD0NXyUYKxY7"},"source":["Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "]},{"cell_type":"markdown","metadata":{"id":"CTa2jNZkKxY8"},"source":["<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"]},{"cell_type":"markdown","metadata":{"id":"5H7wPU0IKxY-"},"source":["\n","Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n","\n","* Вычислить расстояние до каждого из объектов обучающей выборки\n","* Отобрать объектов обучающей выборки, расстояние до которых минимально\n","* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"]},{"cell_type":"markdown","metadata":{"id":"T2docs4225pb"},"source":["Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке."]},{"cell_type":"markdown","metadata":{"id":"AcjJQX3wKxZA"},"source":["### Обработка данных"]},{"cell_type":"code","metadata":{"id":"Ozcx5mVOKxZB","executionInfo":{"status":"ok","timestamp":1614865183630,"user_tz":-180,"elapsed":585,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ry4bMKaUjHJj"},"source":["Сcылка на датасет (лежит в папке): https://drive.google.com/drive/folders/16TSz1P-oTF8iXSQ1xrt0r_VO35xKmUes?usp=sharing"]},{"cell_type":"code","metadata":{"id":"rvPrVRvK25pc","colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"status":"ok","timestamp":1614865278064,"user_tz":-180,"elapsed":914,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"a25ea157-ad05-4d1e-ae29-c2ee5a906e26"},"source":["all_data = pd.read_csv('forest_dataset.csv')\n","all_data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2683</td>\n","      <td>333</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>2743</td>\n","      <td>121</td>\n","      <td>173</td>\n","      <td>179</td>\n","      <td>6572</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2915</td>\n","      <td>90</td>\n","      <td>8</td>\n","      <td>216</td>\n","      <td>11</td>\n","      <td>4433</td>\n","      <td>232</td>\n","      <td>228</td>\n","      <td>129</td>\n","      <td>4019</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2941</td>\n","      <td>162</td>\n","      <td>7</td>\n","      <td>698</td>\n","      <td>76</td>\n","      <td>2783</td>\n","      <td>227</td>\n","      <td>242</td>\n","      <td>148</td>\n","      <td>1784</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3096</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>170</td>\n","      <td>3</td>\n","      <td>3303</td>\n","      <td>231</td>\n","      <td>202</td>\n","      <td>99</td>\n","      <td>5370</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2999</td>\n","      <td>66</td>\n","      <td>8</td>\n","      <td>488</td>\n","      <td>37</td>\n","      <td>1532</td>\n","      <td>228</td>\n","      <td>225</td>\n","      <td>131</td>\n","      <td>2290</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0    1   2    3   4     5    6    7  ...  47  48  49  50  51  52  53  54\n","0  2683  333  35   30  26  2743  121  173  ...   0   0   0   0   0   0   0   2\n","1  2915   90   8  216  11  4433  232  228  ...   0   0   0   0   0   0   0   1\n","2  2941  162   7  698  76  2783  227  242  ...   0   0   0   0   0   0   0   2\n","3  3096   60  17  170   3  3303  231  202  ...   0   0   0   0   0   0   0   1\n","4  2999   66   8  488  37  1532  228  225  ...   0   0   0   0   0   0   0   2\n","\n","[5 rows x 55 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"_o8yXBPSKxZI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614865290727,"user_tz":-180,"elapsed":762,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"9753f633-d359-46ac-efd0-f643289ab43e"},"source":["all_data.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 55)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"A3b5wueVeXG4","executionInfo":{"status":"ok","timestamp":1614865388518,"user_tz":-180,"elapsed":583,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"2ec6c1a8-b114-4ada-d330-1d90117057f5"},"source":["all_data.describe()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.0</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2960.645900</td>\n","      <td>154.127600</td>\n","      <td>13.98120</td>\n","      <td>269.502800</td>\n","      <td>45.596800</td>\n","      <td>2358.805400</td>\n","      <td>212.382200</td>\n","      <td>223.886000</td>\n","      <td>142.892300</td>\n","      <td>1982.005000</td>\n","      <td>0.440600</td>\n","      <td>0.051100</td>\n","      <td>0.445400</td>\n","      <td>0.062900</td>\n","      <td>0.005100</td>\n","      <td>0.014500</td>\n","      <td>0.009400</td>\n","      <td>0.021500</td>\n","      <td>0.00250</td>\n","      <td>0.01030</td>\n","      <td>0.000200</td>\n","      <td>0.000600</td>\n","      <td>0.002600</td>\n","      <td>0.057800</td>\n","      <td>0.019800</td>\n","      <td>0.050900</td>\n","      <td>0.032500</td>\n","      <td>0.000900</td>\n","      <td>0.0</td>\n","      <td>0.003600</td>\n","      <td>0.005000</td>\n","      <td>0.003200</td>\n","      <td>0.00760</td>\n","      <td>0.014600</td>\n","      <td>0.00160</td>\n","      <td>0.05670</td>\n","      <td>0.104100</td>\n","      <td>0.036900</td>\n","      <td>0.000800</td>\n","      <td>0.005000</td>\n","      <td>0.00110</td>\n","      <td>0.001300</td>\n","      <td>0.194400</td>\n","      <td>0.053800</td>\n","      <td>0.047800</td>\n","      <td>0.092300</td>\n","      <td>0.078300</td>\n","      <td>0.002000</td>\n","      <td>0.002900</td>\n","      <td>0.000300</td>\n","      <td>0.000500</td>\n","      <td>0.024000</td>\n","      <td>0.02130</td>\n","      <td>0.012300</td>\n","      <td>2.034100</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>276.101899</td>\n","      <td>111.112044</td>\n","      <td>7.44313</td>\n","      <td>214.741609</td>\n","      <td>57.607363</td>\n","      <td>1564.814207</td>\n","      <td>26.560675</td>\n","      <td>19.443395</td>\n","      <td>37.460182</td>\n","      <td>1307.685368</td>\n","      <td>0.496484</td>\n","      <td>0.220213</td>\n","      <td>0.497035</td>\n","      <td>0.242795</td>\n","      <td>0.071236</td>\n","      <td>0.119546</td>\n","      <td>0.096502</td>\n","      <td>0.145051</td>\n","      <td>0.04994</td>\n","      <td>0.10097</td>\n","      <td>0.014141</td>\n","      <td>0.024489</td>\n","      <td>0.050926</td>\n","      <td>0.233377</td>\n","      <td>0.139319</td>\n","      <td>0.219805</td>\n","      <td>0.177333</td>\n","      <td>0.029988</td>\n","      <td>0.0</td>\n","      <td>0.059895</td>\n","      <td>0.070537</td>\n","      <td>0.056481</td>\n","      <td>0.08685</td>\n","      <td>0.119951</td>\n","      <td>0.03997</td>\n","      <td>0.23128</td>\n","      <td>0.305405</td>\n","      <td>0.188526</td>\n","      <td>0.028274</td>\n","      <td>0.070537</td>\n","      <td>0.03315</td>\n","      <td>0.036034</td>\n","      <td>0.395758</td>\n","      <td>0.225634</td>\n","      <td>0.213353</td>\n","      <td>0.289463</td>\n","      <td>0.268657</td>\n","      <td>0.044679</td>\n","      <td>0.053776</td>\n","      <td>0.017319</td>\n","      <td>0.022356</td>\n","      <td>0.153057</td>\n","      <td>0.14439</td>\n","      <td>0.110227</td>\n","      <td>1.378016</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1866.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>-147.000000</td>\n","      <td>0.000000</td>\n","      <td>70.000000</td>\n","      <td>88.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2819.000000</td>\n","      <td>57.000000</td>\n","      <td>9.00000</td>\n","      <td>108.000000</td>\n","      <td>6.000000</td>\n","      <td>1106.750000</td>\n","      <td>199.000000</td>\n","      <td>213.000000</td>\n","      <td>120.000000</td>\n","      <td>1041.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2996.000000</td>\n","      <td>128.000000</td>\n","      <td>13.00000</td>\n","      <td>218.000000</td>\n","      <td>29.000000</td>\n","      <td>2008.000000</td>\n","      <td>218.000000</td>\n","      <td>227.000000</td>\n","      <td>143.000000</td>\n","      <td>1719.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3162.000000</td>\n","      <td>254.000000</td>\n","      <td>18.00000</td>\n","      <td>390.000000</td>\n","      <td>68.000000</td>\n","      <td>3330.250000</td>\n","      <td>231.000000</td>\n","      <td>238.000000</td>\n","      <td>167.000000</td>\n","      <td>2542.250000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3846.000000</td>\n","      <td>359.000000</td>\n","      <td>57.00000</td>\n","      <td>1370.000000</td>\n","      <td>573.000000</td>\n","      <td>7023.000000</td>\n","      <td>254.000000</td>\n","      <td>254.000000</td>\n","      <td>247.000000</td>\n","      <td>7080.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>7.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  0             1  ...            53            54\n","count  10000.000000  10000.000000  ...  10000.000000  10000.000000\n","mean    2960.645900    154.127600  ...      0.012300      2.034100\n","std      276.101899    111.112044  ...      0.110227      1.378016\n","min     1866.000000      0.000000  ...      0.000000      1.000000\n","25%     2819.000000     57.000000  ...      0.000000      1.000000\n","50%     2996.000000    128.000000  ...      0.000000      2.000000\n","75%     3162.000000    254.000000  ...      0.000000      2.000000\n","max     3846.000000    359.000000  ...      1.000000      7.000000\n","\n","[8 rows x 55 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"itCWxHEY25pg"},"source":["Выделим значения метки класса в переменную `labels`, признаковые описания --- в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."]},{"cell_type":"code","metadata":{"id":"f_YIUOuV25ph","executionInfo":{"status":"ok","timestamp":1614865513490,"user_tz":-180,"elapsed":556,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["labels = all_data[all_data.columns[-1]].values\n","feature_matrix = all_data[all_data.columns[:-1]].values"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FukXaH_r8PMQ"},"source":["### Пара слов о sklearn"]},{"cell_type":"markdown","metadata":{"id":"k5S_0Lfc8PMR"},"source":["**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."]},{"cell_type":"markdown","metadata":{"id":"VhVDEG538PMS"},"source":["`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."]},{"cell_type":"markdown","metadata":{"id":"QJZQulsp8PMT"},"source":["Познакомимся со вспомогательной функцией \n","[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","С её помощью можно разбить выборку на обучающую и тестовую части."]},{"cell_type":"code","metadata":{"id":"Q030jzyY25pl","executionInfo":{"status":"ok","timestamp":1614865511920,"user_tz":-180,"elapsed":1397,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkeB47mX8PMY"},"source":["Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."]},{"cell_type":"code","metadata":{"id":"YJN0jFARKxZX","executionInfo":{"status":"ok","timestamp":1614865517866,"user_tz":-180,"elapsed":578,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n","    feature_matrix, labels, test_size=0.2, random_state=42)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"odC1c7X48PMb"},"source":["Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."]},{"cell_type":"markdown","metadata":{"id":"z3fGvPqG8PMc"},"source":["Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n","\n","В качестве примера модели можно привести классификаторы\n","[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n","[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."]},{"cell_type":"markdown","metadata":{"id":"IuX8Rc7c8PMd"},"source":["У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."]},{"cell_type":"markdown","metadata":{"id":"ZYokUkxO8PMe"},"source":["Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n","\n","У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n","\n","Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n","\n","Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n","\n","Рассмотрим всё это на примере логистической регрессии."]},{"cell_type":"code","metadata":{"id":"ew0Ji_2D8PMe","executionInfo":{"status":"ok","timestamp":1614865783820,"user_tz":-180,"elapsed":708,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9KcMHXr8PMh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614865966387,"user_tz":-180,"elapsed":1568,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"4f9c57a5-6ff8-4afb-d840-172c29ffb563"},"source":["# создание модели с указанием гиперпараметра C\n","clf = LogisticRegression(C=1)\n","# clf = LogisticRegression()\n","# обучение модели\n","clf.fit(train_feature_matrix, train_labels)\n","# предсказание на тестовой выборке\n","y_pred = clf.predict(test_feature_matrix)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wb0ll03qgmB-","executionInfo":{"status":"ok","timestamp":1614865920243,"user_tz":-180,"elapsed":567,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"6ca6f21d-80c9-451a-d15a-cfd8ecc0696e"},"source":["train_feature_matrix, train_labels"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[3001,  322,   11, ...,    0,    0,    0],\n","        [2916,  168,   23, ...,    0,    0,    0],\n","        [3216,  161,   32, ...,    0,    1,    0],\n","        ...,\n","        [3142,   33,    7, ...,    0,    0,    0],\n","        [2335,  295,   34, ...,    0,    0,    0],\n","        [3094,  328,   12, ...,    0,    0,    0]]),\n"," array([1, 2, 7, ..., 2, 3, 1]))"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"h3gjg3pm8PMm"},"source":["Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."]},{"cell_type":"code","metadata":{"id":"J2Ej1Lni8PMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614865971053,"user_tz":-180,"elapsed":574,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"af415f60-252f-4165-e555-cd8be2db43f5"},"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_labels, y_pred)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6075"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"malIDW_P8PMp"},"source":["Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n","\n","Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n","\n","У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."]},{"cell_type":"code","metadata":{"id":"vq687Aoc8PMq","executionInfo":{"status":"ok","timestamp":1614866223431,"user_tz":-180,"elapsed":771,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxkku5hdhOUu","executionInfo":{"status":"ok","timestamp":1614866089191,"user_tz":-180,"elapsed":638,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}}},"source":["?LogisticRegression"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVnqHBvK8PMs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614866318200,"user_tz":-180,"elapsed":85236,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"1dcc1d88-6a07-42bd-d122-02db587f59ad"},"source":["# заново создадим модель, указав солвер\n","clf = LogisticRegression(solver='saga')\n","\n","# опишем сетку, по которой будем искать\n","param_grid = {\n","    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\n","    'penalty': ['l1', 'l2'],\n","}\n","\n","# создадим объект GridSearchCV\n","search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n","\n","# запустим поиск\n","search.fit(feature_matrix, labels)\n","\n","# выведем наилучшие параметры\n","print(search.best_params_)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["{'C': 1, 'penalty': 'l2'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"DnVTFcvZ8PMv"},"source":["В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."]},{"cell_type":"code","metadata":{"id":"ArKINrE_8PMw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614866319563,"user_tz":-180,"elapsed":1360,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"b8e25249-e259-4426-9772-35711b4f0778"},"source":["accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6419"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"okzpKY_I8PMz"},"source":["Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."]},{"cell_type":"markdown","metadata":{"id":"_mdJyxdo8PM1"},"source":["В заданиях вам предстоит повторить это для метода ближайших соседей."]},{"cell_type":"markdown","metadata":{"id":"z8W__017KxZc"},"source":["### Обучение модели"]},{"cell_type":"markdown","metadata":{"id":"02uT6CPYKxZe"},"source":["Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n","\n","* число соседей `n_neighbors`\n","* метрика расстояния между объектами `metric`\n","* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"]},{"cell_type":"markdown","metadata":{"id":"BHVNCaJ325qD"},"source":["Обучите на датасете `KNeighborsClassifier` из `sklearn`."]},{"cell_type":"code","metadata":{"id":"o4CMnnOY25qD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614869052533,"user_tz":-180,"elapsed":22907,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"4fa6e018-2b58-4984-87b8-512d7bd2d220"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","clf = KNeighborsClassifier()\n","\n","params = {'n_neighbors': range(1,11),\n","          'metric': ['manhattan', 'euclidean'],\n","          'weights': ['uniform', 'distance']}\n","\n","clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n","\n","clf_grid.fit(train_feature_matrix, train_labels)\n","print(clf_grid.best_params_)\n","\n","accuracy_score(test_labels, clf_grid.best_estimator_.predict(test_feature_matrix))\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.785"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"r_2Mf8BiKxZk"},"source":["### Вопрос 1:\n","* Какое качество у вас получилось?"]},{"cell_type":"markdown","metadata":{"id":"uFTIaPdrKxZl"},"source":["Подберём параметры нашей модели"]},{"cell_type":"markdown","metadata":{"id":"8WzoRJZd25qF"},"source":["* Переберите по сетке от `1` до `10` параметр числа соседей\n","\n","* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n","\n","* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"]},{"cell_type":"code","metadata":{"id":"4lMSy-6f25qG","scrolled":true},"source":["from sklearn.model_selection import GridSearchCV\n","params = # Ваш код здесь\n","\n","clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n","# Теперь обучение. Ваш код здесь"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SO7E6G8jKxZp"},"source":["Выведем лучшие параметры"]},{"cell_type":"code","metadata":{"id":"md48pHrMKxZq"},"source":["clf_grid.best_params_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M05n9l8pKxZt"},"source":["### Вопрос 2:\n","* Какую metric следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"Pmjx38OoKxZt"},"source":["### Вопрос 3:\n","* Сколько n_neighbors следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"eqLeJUP8KxZu"},"source":["### Вопрос 4:\n","* Какой тип weights следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"aBmiDbvV25qI"},"source":["Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."]},{"cell_type":"code","metadata":{"id":"ig_vS8O925qI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614869505792,"user_tz":-180,"elapsed":554,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"93e1b8fb-1ae2-4411-ba19-c4b8d46bee5a"},"source":["optimal_clf = KNeighborsClassifier(n_neighbors=4).fit(train_feature_matrix, train_labels)\n","pred_prob = optimal_clf.predict_proba(test_feature_matrix)\n","pred_prob\n"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 1.  , 0.  , ..., 0.  , 0.  , 0.  ],\n","       [0.75, 0.25, 0.  , ..., 0.  , 0.  , 0.  ],\n","       [0.5 , 0.5 , 0.  , ..., 0.  , 0.  , 0.  ],\n","       ...,\n","       [1.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n","       [0.  , 1.  , 0.  , ..., 0.  , 0.  , 0.  ],\n","       [0.5 , 0.  , 0.  , ..., 0.  , 0.  , 0.5 ]])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mLgatH-uaHT","executionInfo":{"status":"ok","timestamp":1614869605147,"user_tz":-180,"elapsed":559,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"eeb85510-316c-45b1-abe1-48b1214d2625"},"source":["unique, freq = np.unique(test_labels, return_counts=True)\n","freq = list(map(lambda x: x / len(test_labels),freq))\n","unique, freq"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1, 2, 3, 4, 5, 6, 7]),\n"," [0.368, 0.4865, 0.0555, 0.0055, 0.0165, 0.028, 0.04])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"5KZltGLzvAso","executionInfo":{"status":"ok","timestamp":1614869732520,"user_tz":-180,"elapsed":564,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"f2df89b9-c8ca-4984-c774-6ad6c8968b9f"},"source":["pd.DataFrame(pred_prob)"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.75</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.50</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>0.00</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1996</th>\n","      <td>0.75</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1998</th>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1999</th>\n","      <td>0.50</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 7 columns</p>\n","</div>"],"text/plain":["         0     1    2    3    4     5    6\n","0     0.00  1.00  0.0  0.0  0.0  0.00  0.0\n","1     0.75  0.25  0.0  0.0  0.0  0.00  0.0\n","2     0.50  0.50  0.0  0.0  0.0  0.00  0.0\n","3     1.00  0.00  0.0  0.0  0.0  0.00  0.0\n","4     0.00  1.00  0.0  0.0  0.0  0.00  0.0\n","...    ...   ...  ...  ...  ...   ...  ...\n","1995  0.00  0.25  0.0  0.0  0.0  0.75  0.0\n","1996  0.75  0.25  0.0  0.0  0.0  0.00  0.0\n","1997  1.00  0.00  0.0  0.0  0.0  0.00  0.0\n","1998  0.00  1.00  0.0  0.0  0.0  0.00  0.0\n","1999  0.50  0.00  0.0  0.0  0.0  0.00  0.5\n","\n","[2000 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_7UiWQtuzyF","executionInfo":{"status":"ok","timestamp":1614869811527,"user_tz":-180,"elapsed":599,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"c26cbcaf-41c0-401a-9183-7546290d9af9"},"source":["pred_prob.mean(axis=0)[2]"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.05325"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"2kkapT38KxZz","colab":{"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"status":"ok","timestamp":1614869510768,"user_tz":-180,"elapsed":923,"user":{"displayName":"Andrey T","photoUrl":"","userId":"15869720638483276681"}},"outputId":"5f73f9b4-a859-40f0-a35c-0d18faf82ce4"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","\n","unique, freq = np.unique(test_labels, return_counts=True)\n","freq = list(map(lambda x: x / len(test_labels),freq))\n","\n","pred_freq = pred_prob.mean(axis=0)\n","plt.figure(figsize=(10, 8))\n","plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n","plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n","plt.ylim(0, 0.54)\n","plt.legend()\n","plt.show()"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"gp4uDyLmKxZ3"},"source":["### Вопрос 5:\n","* Какая прогнозируемая вероятность pred_freq класса под номером 3 (до 2 знаков после запятой)?"]}]}